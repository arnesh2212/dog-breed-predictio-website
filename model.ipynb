{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 120 classes.\n",
      "Found 8580 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "IMG_SHAPE = (200,200,3)\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255 , \n",
    "                                  rotation_range = 0.4 ,\n",
    "                                  horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training = train_datagen.flow_from_directory(\"train\" ,\n",
    "                                            target_size = (200,200),\n",
    "                                            class_mode = \"categorical\",\n",
    "                                            batch_size = 40)\n",
    "\n",
    "validation = test_datagen.flow_from_directory(\"test\" ,\n",
    "                                            target_size = (200,200),\n",
    "                                            class_mode = \"categorical\",\n",
    "                                            batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "base_model.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dense(120, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 93s 303ms/step - loss: 1.0261 - accuracy: 0.7734 - top_k_categorical_accuracy: 0.9751 - val_loss: 1.1042 - val_accuracy: 0.7371 - val_top_k_categorical_accuracy: 0.9624\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 90s 299ms/step - loss: 0.9880 - accuracy: 0.7795 - top_k_categorical_accuracy: 0.9769 - val_loss: 1.0779 - val_accuracy: 0.7396 - val_top_k_categorical_accuracy: 0.9626\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 89s 296ms/step - loss: 0.9595 - accuracy: 0.7849 - top_k_categorical_accuracy: 0.9779 - val_loss: 1.0538 - val_accuracy: 0.7425 - val_top_k_categorical_accuracy: 0.9634\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 89s 297ms/step - loss: 0.9323 - accuracy: 0.7898 - top_k_categorical_accuracy: 0.9796 - val_loss: 1.0325 - val_accuracy: 0.7456 - val_top_k_categorical_accuracy: 0.9640\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 89s 298ms/step - loss: 0.9104 - accuracy: 0.7893 - top_k_categorical_accuracy: 0.9796 - val_loss: 1.0123 - val_accuracy: 0.7472 - val_top_k_categorical_accuracy: 0.9645\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 89s 296ms/step - loss: 0.8879 - accuracy: 0.7935 - top_k_categorical_accuracy: 0.9806 - val_loss: 0.9944 - val_accuracy: 0.7510 - val_top_k_categorical_accuracy: 0.9648\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 88s 295ms/step - loss: 0.8676 - accuracy: 0.7982 - top_k_categorical_accuracy: 0.9796 - val_loss: 0.9776 - val_accuracy: 0.7544 - val_top_k_categorical_accuracy: 0.9662\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 89s 295ms/step - loss: 0.8470 - accuracy: 0.8002 - top_k_categorical_accuracy: 0.9812 - val_loss: 0.9617 - val_accuracy: 0.7558 - val_top_k_categorical_accuracy: 0.9668\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 88s 294ms/step - loss: 0.8315 - accuracy: 0.8012 - top_k_categorical_accuracy: 0.9815 - val_loss: 0.9478 - val_accuracy: 0.7590 - val_top_k_categorical_accuracy: 0.9675\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 88s 295ms/step - loss: 0.8164 - accuracy: 0.8005 - top_k_categorical_accuracy: 0.9818 - val_loss: 0.9343 - val_accuracy: 0.7617 - val_top_k_categorical_accuracy: 0.9678\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adamax(0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
    "history = model.fit(training,\n",
    "                    epochs=10,\n",
    "                    validation_data = validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
